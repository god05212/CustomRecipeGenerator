import collections, re
import numpy as np, pandas as pd, matplotlib.pyplot as plt
from wordcloud import WordCloud
from konlpy.tag import Okt
import streamlit as st
from transformers import pipeline

st.set_page_config("í…ìŠ¤íŠ¸ ë¶„ì„ ëŒ€ì‹œë³´ë“œ(HF)", "ğŸ§ ", layout="wide")

# âœ… Hugging Face í•œêµ­ì–´ ê°ì„±ëª¨ë¸ (NSMC)
#  - ì¶œë ¥ ì˜ˆ: [{'label': 'positive', 'score': 0.99}]
clf = pipeline("sentiment-analysis", model="daekeun-ml/koelectra-small-v3-nsmc")

okt = Okt()
STOP = set(["ê·¸ë¦¬ê³ ","ê·¸ëŸ¬ë‚˜","í•˜ì§€ë§Œ","ë˜í•œ","ì´ë¯¸","ì´ê²ƒ","ì €ê²ƒ","ê·¸","ê²ƒ","ìˆ˜","ë“±","ë°","ì—ì„œ","ìœ¼ë¡œ","ì—ê²Œ","ë³´ë‹¤","ì´ë‹¤","í•˜ë‹¤"])

# í…ŒìŠ¤íŠ¸ ë°ì´í„° 5ê°€ì§€
SAMPLES = {
 "ë¦¬ë·°A":"ë°°ë‹¬ì´ ë¹¨ëê³  ìŒì‹ì´ ì •ë§ ë§›ìˆì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì£¼ë¬¸í•  ì˜ì‚¬ ìˆì–´ìš”!",
 "ë¦¬ë·°B":"ê°€ê²© ëŒ€ë¹„ í’ˆì§ˆì´ ë³„ë¡œì˜€ìŠµë‹ˆë‹¤. ì–‘ë„ ì ê³  í¬ì¥ë„ í—ˆìˆ í–ˆì–´ìš”.",
 "ë‰´ìŠ¤A":"ë„ì‹œ ì¬ìƒ í”„ë¡œì íŠ¸ê°€ ë³¸ê²©í™”ë˜ë©° ì§€ì—­ ìƒê¶Œì— í™œê¸°ê°€ ëŒê³  ìˆë‹¤.",
 "í”¼ë“œë°±A":"UIê°€ ì§ê´€ì ì´ì§€ë§Œ ë¡œë”© ì†ë„ê°€ ëŠë ¤ì„œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.",
 "ì¼ê¸°A":"ì˜¤ëŠ˜ì€ ë¹„ê°€ ë‚´ë ¸ì§€ë§Œ ì‚°ì±…ì„ í•˜ë‹ˆ ë§ˆìŒì´ í•œê²° í¸ì•ˆí•´ì¡Œë‹¤."
}

def tokenize_ko(text):
    toks = [w for w,t in okt.pos(text, stem=True) if t in ("Noun","Adjective","Verb")]
    return [w for w in toks if w not in STOP and len(w)>1]

def stats(text):
    toks = tokenize_ko(text)
    return {
        "ë¬¸ììˆ˜": len(text),
        "ë‹¨ì–´ìˆ˜": len(toks),
        "ê³ ìœ ë‹¨ì–´ìˆ˜": len(set(toks)),
        "í‰ê· ë‹¨ì–´ê¸¸ì´": round(np.mean([len(t) for t in toks]) if toks else 0,2)
    }, toks

def freq_df(tokens, topk=20):
    c = collections.Counter(tokens).most_common(topk)
    return pd.DataFrame(c, columns=["ë‹¨ì–´","ë¹ˆë„"])

def sentiment_hf(text):
    out = clf(text[:512])[0]  # ê¸¸ë©´ ì˜ë¼ ì²˜ë¦¬
    label = "ê¸ì •ğŸ™‚" if out["label"] == "positive" else "ë¶€ì •ğŸ™"
    return label, float(out["score"])

st.title("ğŸ§  í…ìŠ¤íŠ¸ ë¶„ì„ ëŒ€ì‹œë³´ë“œ â€” Hugging Face í•œêµ­ì–´ ëª¨ë¸ ì ìš©")
c1, c2 = st.columns([2,3])

with c1:
    st.subheader("â‘  í…ìŠ¤íŠ¸ ì…ë ¥")
    pick = st.selectbox("ìƒ˜í”Œ ì„ íƒ", list(SAMPLES.keys()))
    text = st.text_area("ì§ì ‘ ì…ë ¥(ì„ íƒ). ë¹„ìš°ë©´ ìƒ˜í”Œ ì‚¬ìš©", height=140)
    text = (text or SAMPLES[pick]).strip()
    st.caption("ìƒ˜í”Œ 5ê°€ì§€: " + ", ".join(SAMPLES.keys()))

    st.subheader("â‘¡ í†µê³„ ë¶„ì„")
    S, toks = stats(text)
    st.dataframe(pd.DataFrame([S]), use_container_width=True)

    st.subheader("â‘¢ ë¹ˆë„ ë¶„ì„")
    topk = st.slider("ìƒìœ„ n ë‹¨ì–´", 5, 30, 15)
    fdf = freq_df(toks, topk)
    st.dataframe(fdf, use_container_width=True)

with c2:
    st.subheader("â‘£ ê·¸ë˜í”„ / ì›Œë“œí´ë¼ìš°ë“œ")
    if len(fdf):
        st.bar_chart(fdf.set_index("ë‹¨ì–´")["ë¹ˆë„"])
        wc = WordCloud(font_path="/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
                       background_color="white", width=800, height=300)
        fig = plt.figure(figsize=(8,3)); plt.axis("off")
        plt.imshow(wc.generate_from_frequencies(dict(zip(fdf["ë‹¨ì–´"], fdf["ë¹ˆë„"]))))
        st.pyplot(fig, use_container_width=True)

    st.subheader("â‘¤ ê°ì„± ë¶„ì„ (Hugging Face)")
    label, prob = sentiment_hf(text)
    st.metric("ê°ì„±", label, delta=round((prob*100),2))
    with st.expander("í† í° ë¯¸ë¦¬ë³´ê¸°"):
        st.write(toks)

st.divider()
st.caption("Flow: ì…ë ¥ â†’ í†µê³„ â†’ ë¹ˆë„ â†’ ì‹œê°í™” â†’ ê°ì„±(HF koELECTRA)")
